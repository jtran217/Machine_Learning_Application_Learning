{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e0ff5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['male' 22.0 3]\n",
      " ['female' 38.0 1]\n",
      " ['female' 26.0 3]\n",
      " ...\n",
      " ['female' nan 3]\n",
      " ['male' 26.0 1]\n",
      " ['male' 32.0 3]]\n"
     ]
    }
   ],
   "source": [
    "### Import Dataset:\n",
    "\n",
    "ds = pd.read_csv(\"./data/Titanic-Dataset.csv\")\n",
    "\n",
    "# Separating our dependend and independent variable:\n",
    "#x = ds[[\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Pclass\",\"Fare\"]].values\n",
    "\n",
    "# Using only sex,age,Pclass as feature resulted in highest accuracy from the logistical Regression model\n",
    "x = ds[[\"Sex\",\"Age\",\"Pclass\"]].values\n",
    "print(x)\n",
    "y = ds[[\"Survived\"]].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "61cb4efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning: \n",
      "[22.0 38.0 26.0 35.0 35.0 nan 54.0 2.0 27.0 14.0 4.0 58.0 20.0 39.0 14.0\n",
      " 55.0 2.0 nan 31.0 nan 35.0 34.0 15.0 28.0 8.0 38.0 nan 19.0 nan nan 40.0\n",
      " nan nan 66.0 28.0 42.0 nan 21.0 18.0 14.0 40.0 27.0 nan 3.0 19.0 nan nan\n",
      " nan nan 18.0 7.0 21.0 49.0 29.0 65.0 nan 21.0 28.5 5.0 11.0 22.0 38.0\n",
      " 45.0 4.0 nan nan 29.0 19.0 17.0 26.0 32.0 16.0 21.0 26.0 32.0 25.0 nan\n",
      " nan 0.83 30.0 22.0 29.0 nan 28.0 17.0 33.0 16.0 nan 23.0 24.0 29.0 20.0\n",
      " 46.0 26.0 59.0 nan 71.0 23.0 34.0 34.0 28.0 nan 21.0 33.0 37.0 28.0 21.0\n",
      " nan 38.0 nan 47.0 14.5 22.0 20.0 17.0 21.0 70.5 29.0 24.0 2.0 21.0 nan\n",
      " 32.5 32.5 54.0 12.0 nan 24.0 nan 45.0 33.0 20.0 47.0 29.0 25.0 23.0 19.0\n",
      " 37.0 16.0 24.0 nan 22.0 24.0 19.0 18.0 19.0 27.0 9.0 36.5 42.0 51.0 22.0\n",
      " 55.5 40.5 nan 51.0 16.0 30.0 nan nan 44.0 40.0 26.0 17.0 1.0 9.0 nan 45.0\n",
      " nan 28.0 61.0 4.0 1.0 21.0 56.0 18.0 nan 50.0 30.0 36.0 nan nan 9.0 1.0\n",
      " 4.0 nan nan 45.0 40.0 36.0 32.0 19.0 19.0 3.0 44.0 58.0 nan 42.0 nan 24.0\n",
      " 28.0 nan 34.0 45.5 18.0 2.0 32.0 26.0 16.0 40.0 24.0 35.0 22.0 30.0 nan\n",
      " 31.0 27.0 42.0 32.0 30.0 16.0 27.0 51.0 nan 38.0 22.0 19.0 20.5 18.0 nan\n",
      " 35.0 29.0 59.0 5.0 24.0 nan 44.0 8.0 19.0 33.0 nan nan 29.0 22.0 30.0\n",
      " 44.0 25.0 24.0 37.0 54.0 nan 29.0 62.0 30.0 41.0 29.0 nan 30.0 35.0 50.0\n",
      " nan 3.0 52.0 40.0 nan 36.0 16.0 25.0 58.0 35.0 nan 25.0 41.0 37.0 nan\n",
      " 63.0 45.0 nan 7.0 35.0 65.0 28.0 16.0 19.0 nan 33.0 30.0 22.0 42.0 22.0\n",
      " 26.0 19.0 36.0 24.0 24.0 nan 23.5 2.0 nan 50.0 nan nan 19.0 nan nan 0.92\n",
      " nan 17.0 30.0 30.0 24.0 18.0 26.0 28.0 43.0 26.0 24.0 54.0 31.0 40.0 22.0\n",
      " 27.0 30.0 22.0 nan 36.0 61.0 36.0 31.0 16.0 nan 45.5 38.0 16.0 nan nan\n",
      " 29.0 41.0 45.0 45.0 2.0 24.0 28.0 25.0 36.0 24.0 40.0 nan 3.0 42.0 23.0\n",
      " nan 15.0 25.0 nan 28.0 22.0 38.0 nan nan 40.0 29.0 45.0 35.0 nan 30.0\n",
      " 60.0 nan nan 24.0 25.0 18.0 19.0 22.0 3.0 nan 22.0 27.0 20.0 19.0 42.0\n",
      " 1.0 32.0 35.0 nan 18.0 1.0 36.0 nan 17.0 36.0 21.0 28.0 23.0 24.0 22.0\n",
      " 31.0 46.0 23.0 28.0 39.0 26.0 21.0 28.0 20.0 34.0 51.0 3.0 21.0 nan nan\n",
      " nan 33.0 nan 44.0 nan 34.0 18.0 30.0 10.0 nan 21.0 29.0 28.0 18.0 nan\n",
      " 28.0 19.0 nan 32.0 28.0 nan 42.0 17.0 50.0 14.0 21.0 24.0 64.0 31.0 45.0\n",
      " 20.0 25.0 28.0 nan 4.0 13.0 34.0 5.0 52.0 36.0 nan 30.0 49.0 nan 29.0\n",
      " 65.0 nan 50.0 nan 48.0 34.0 47.0 48.0 nan 38.0 nan 56.0 nan 0.75 nan 38.0\n",
      " 33.0 23.0 22.0 nan 34.0 29.0 22.0 2.0 9.0 nan 50.0 63.0 25.0 nan 35.0\n",
      " 58.0 30.0 9.0 nan 21.0 55.0 71.0 21.0 nan 54.0 nan 25.0 24.0 17.0 21.0\n",
      " nan 37.0 16.0 18.0 33.0 nan 28.0 26.0 29.0 nan 36.0 54.0 24.0 47.0 34.0\n",
      " nan 36.0 32.0 30.0 22.0 nan 44.0 nan 40.5 50.0 nan 39.0 23.0 2.0 nan 17.0\n",
      " nan 30.0 7.0 45.0 30.0 nan 22.0 36.0 9.0 11.0 32.0 50.0 64.0 19.0 nan\n",
      " 33.0 8.0 17.0 27.0 nan 22.0 22.0 62.0 48.0 nan 39.0 36.0 nan 40.0 28.0\n",
      " nan nan 24.0 19.0 29.0 nan 32.0 62.0 53.0 36.0 nan 16.0 19.0 34.0 39.0\n",
      " nan 32.0 25.0 39.0 54.0 36.0 nan 18.0 47.0 60.0 22.0 nan 35.0 52.0 47.0\n",
      " nan 37.0 36.0 nan 49.0 nan 49.0 24.0 nan nan 44.0 35.0 36.0 30.0 27.0\n",
      " 22.0 40.0 39.0 nan nan nan 35.0 24.0 34.0 26.0 4.0 26.0 27.0 42.0 20.0\n",
      " 21.0 21.0 61.0 57.0 21.0 26.0 nan 80.0 51.0 32.0 nan 9.0 28.0 32.0 31.0\n",
      " 41.0 nan 20.0 24.0 2.0 nan 0.75 48.0 19.0 56.0 nan 23.0 nan 18.0 21.0 nan\n",
      " 18.0 24.0 nan 32.0 23.0 58.0 50.0 40.0 47.0 36.0 20.0 32.0 25.0 nan 43.0\n",
      " nan 40.0 31.0 70.0 31.0 nan 18.0 24.5 18.0 43.0 36.0 nan 27.0 20.0 14.0\n",
      " 60.0 25.0 14.0 19.0 18.0 15.0 31.0 4.0 nan 25.0 60.0 52.0 44.0 nan 49.0\n",
      " 42.0 18.0 35.0 18.0 25.0 26.0 39.0 45.0 42.0 22.0 nan 24.0 nan 48.0 29.0\n",
      " 52.0 19.0 38.0 27.0 nan 33.0 6.0 17.0 34.0 50.0 27.0 20.0 30.0 nan 25.0\n",
      " 25.0 29.0 11.0 nan 23.0 23.0 28.5 48.0 35.0 nan nan nan 36.0 21.0 24.0\n",
      " 31.0 70.0 16.0 30.0 19.0 31.0 4.0 6.0 33.0 23.0 48.0 0.67 28.0 18.0 34.0\n",
      " 33.0 nan 41.0 20.0 36.0 16.0 51.0 nan 30.5 nan 32.0 24.0 48.0 57.0 nan\n",
      " 54.0 18.0 nan 5.0 nan 43.0 13.0 17.0 29.0 nan 25.0 25.0 18.0 8.0 1.0 46.0\n",
      " nan 16.0 nan nan 25.0 39.0 49.0 31.0 30.0 30.0 34.0 31.0 11.0 0.42 27.0\n",
      " 31.0 39.0 18.0 39.0 33.0 26.0 39.0 35.0 6.0 30.5 nan 23.0 31.0 43.0 10.0\n",
      " 52.0 27.0 38.0 27.0 2.0 nan nan 1.0 nan 62.0 15.0 0.83 nan 23.0 18.0 39.0\n",
      " 21.0 nan 32.0 nan 20.0 16.0 30.0 34.5 17.0 42.0 nan 35.0 28.0 nan 4.0\n",
      " 74.0 9.0 16.0 44.0 18.0 45.0 51.0 24.0 nan 41.0 21.0 48.0 nan 24.0 42.0\n",
      " 27.0 31.0 nan 4.0 26.0 47.0 33.0 47.0 28.0 15.0 20.0 19.0 nan 56.0 25.0\n",
      " 33.0 22.0 28.0 25.0 39.0 27.0 19.0 nan 26.0 32.0]\n",
      "After Cleaning\n",
      "[22.0 38.0 26.0 35.0 35.0 29.69911764705882 54.0 2.0 27.0 14.0 4.0 58.0\n",
      " 20.0 39.0 14.0 55.0 2.0 29.69911764705882 31.0 29.69911764705882 35.0\n",
      " 34.0 15.0 28.0 8.0 38.0 29.69911764705882 19.0 29.69911764705882\n",
      " 29.69911764705882 40.0 29.69911764705882 29.69911764705882 66.0 28.0 42.0\n",
      " 29.69911764705882 21.0 18.0 14.0 40.0 27.0 29.69911764705882 3.0 19.0\n",
      " 29.69911764705882 29.69911764705882 29.69911764705882 29.69911764705882\n",
      " 18.0 7.0 21.0 49.0 29.0 65.0 29.69911764705882 21.0 28.5 5.0 11.0 22.0\n",
      " 38.0 45.0 4.0 29.69911764705882 29.69911764705882 29.0 19.0 17.0 26.0\n",
      " 32.0 16.0 21.0 26.0 32.0 25.0 29.69911764705882 29.69911764705882 0.83\n",
      " 30.0 22.0 29.0 29.69911764705882 28.0 17.0 33.0 16.0 29.69911764705882\n",
      " 23.0 24.0 29.0 20.0 46.0 26.0 59.0 29.69911764705882 71.0 23.0 34.0 34.0\n",
      " 28.0 29.69911764705882 21.0 33.0 37.0 28.0 21.0 29.69911764705882 38.0\n",
      " 29.69911764705882 47.0 14.5 22.0 20.0 17.0 21.0 70.5 29.0 24.0 2.0 21.0\n",
      " 29.69911764705882 32.5 32.5 54.0 12.0 29.69911764705882 24.0\n",
      " 29.69911764705882 45.0 33.0 20.0 47.0 29.0 25.0 23.0 19.0 37.0 16.0 24.0\n",
      " 29.69911764705882 22.0 24.0 19.0 18.0 19.0 27.0 9.0 36.5 42.0 51.0 22.0\n",
      " 55.5 40.5 29.69911764705882 51.0 16.0 30.0 29.69911764705882\n",
      " 29.69911764705882 44.0 40.0 26.0 17.0 1.0 9.0 29.69911764705882 45.0\n",
      " 29.69911764705882 28.0 61.0 4.0 1.0 21.0 56.0 18.0 29.69911764705882 50.0\n",
      " 30.0 36.0 29.69911764705882 29.69911764705882 9.0 1.0 4.0\n",
      " 29.69911764705882 29.69911764705882 45.0 40.0 36.0 32.0 19.0 19.0 3.0\n",
      " 44.0 58.0 29.69911764705882 42.0 29.69911764705882 24.0 28.0\n",
      " 29.69911764705882 34.0 45.5 18.0 2.0 32.0 26.0 16.0 40.0 24.0 35.0 22.0\n",
      " 30.0 29.69911764705882 31.0 27.0 42.0 32.0 30.0 16.0 27.0 51.0\n",
      " 29.69911764705882 38.0 22.0 19.0 20.5 18.0 29.69911764705882 35.0 29.0\n",
      " 59.0 5.0 24.0 29.69911764705882 44.0 8.0 19.0 33.0 29.69911764705882\n",
      " 29.69911764705882 29.0 22.0 30.0 44.0 25.0 24.0 37.0 54.0\n",
      " 29.69911764705882 29.0 62.0 30.0 41.0 29.0 29.69911764705882 30.0 35.0\n",
      " 50.0 29.69911764705882 3.0 52.0 40.0 29.69911764705882 36.0 16.0 25.0\n",
      " 58.0 35.0 29.69911764705882 25.0 41.0 37.0 29.69911764705882 63.0 45.0\n",
      " 29.69911764705882 7.0 35.0 65.0 28.0 16.0 19.0 29.69911764705882 33.0\n",
      " 30.0 22.0 42.0 22.0 26.0 19.0 36.0 24.0 24.0 29.69911764705882 23.5 2.0\n",
      " 29.69911764705882 50.0 29.69911764705882 29.69911764705882 19.0\n",
      " 29.69911764705882 29.69911764705882 0.92 29.69911764705882 17.0 30.0 30.0\n",
      " 24.0 18.0 26.0 28.0 43.0 26.0 24.0 54.0 31.0 40.0 22.0 27.0 30.0 22.0\n",
      " 29.69911764705882 36.0 61.0 36.0 31.0 16.0 29.69911764705882 45.5 38.0\n",
      " 16.0 29.69911764705882 29.69911764705882 29.0 41.0 45.0 45.0 2.0 24.0\n",
      " 28.0 25.0 36.0 24.0 40.0 29.69911764705882 3.0 42.0 23.0\n",
      " 29.69911764705882 15.0 25.0 29.69911764705882 28.0 22.0 38.0\n",
      " 29.69911764705882 29.69911764705882 40.0 29.0 45.0 35.0 29.69911764705882\n",
      " 30.0 60.0 29.69911764705882 29.69911764705882 24.0 25.0 18.0 19.0 22.0\n",
      " 3.0 29.69911764705882 22.0 27.0 20.0 19.0 42.0 1.0 32.0 35.0\n",
      " 29.69911764705882 18.0 1.0 36.0 29.69911764705882 17.0 36.0 21.0 28.0\n",
      " 23.0 24.0 22.0 31.0 46.0 23.0 28.0 39.0 26.0 21.0 28.0 20.0 34.0 51.0 3.0\n",
      " 21.0 29.69911764705882 29.69911764705882 29.69911764705882 33.0\n",
      " 29.69911764705882 44.0 29.69911764705882 34.0 18.0 30.0 10.0\n",
      " 29.69911764705882 21.0 29.0 28.0 18.0 29.69911764705882 28.0 19.0\n",
      " 29.69911764705882 32.0 28.0 29.69911764705882 42.0 17.0 50.0 14.0 21.0\n",
      " 24.0 64.0 31.0 45.0 20.0 25.0 28.0 29.69911764705882 4.0 13.0 34.0 5.0\n",
      " 52.0 36.0 29.69911764705882 30.0 49.0 29.69911764705882 29.0 65.0\n",
      " 29.69911764705882 50.0 29.69911764705882 48.0 34.0 47.0 48.0\n",
      " 29.69911764705882 38.0 29.69911764705882 56.0 29.69911764705882 0.75\n",
      " 29.69911764705882 38.0 33.0 23.0 22.0 29.69911764705882 34.0 29.0 22.0\n",
      " 2.0 9.0 29.69911764705882 50.0 63.0 25.0 29.69911764705882 35.0 58.0 30.0\n",
      " 9.0 29.69911764705882 21.0 55.0 71.0 21.0 29.69911764705882 54.0\n",
      " 29.69911764705882 25.0 24.0 17.0 21.0 29.69911764705882 37.0 16.0 18.0\n",
      " 33.0 29.69911764705882 28.0 26.0 29.0 29.69911764705882 36.0 54.0 24.0\n",
      " 47.0 34.0 29.69911764705882 36.0 32.0 30.0 22.0 29.69911764705882 44.0\n",
      " 29.69911764705882 40.5 50.0 29.69911764705882 39.0 23.0 2.0\n",
      " 29.69911764705882 17.0 29.69911764705882 30.0 7.0 45.0 30.0\n",
      " 29.69911764705882 22.0 36.0 9.0 11.0 32.0 50.0 64.0 19.0\n",
      " 29.69911764705882 33.0 8.0 17.0 27.0 29.69911764705882 22.0 22.0 62.0\n",
      " 48.0 29.69911764705882 39.0 36.0 29.69911764705882 40.0 28.0\n",
      " 29.69911764705882 29.69911764705882 24.0 19.0 29.0 29.69911764705882 32.0\n",
      " 62.0 53.0 36.0 29.69911764705882 16.0 19.0 34.0 39.0 29.69911764705882\n",
      " 32.0 25.0 39.0 54.0 36.0 29.69911764705882 18.0 47.0 60.0 22.0\n",
      " 29.69911764705882 35.0 52.0 47.0 29.69911764705882 37.0 36.0\n",
      " 29.69911764705882 49.0 29.69911764705882 49.0 24.0 29.69911764705882\n",
      " 29.69911764705882 44.0 35.0 36.0 30.0 27.0 22.0 40.0 39.0\n",
      " 29.69911764705882 29.69911764705882 29.69911764705882 35.0 24.0 34.0 26.0\n",
      " 4.0 26.0 27.0 42.0 20.0 21.0 21.0 61.0 57.0 21.0 26.0 29.69911764705882\n",
      " 80.0 51.0 32.0 29.69911764705882 9.0 28.0 32.0 31.0 41.0\n",
      " 29.69911764705882 20.0 24.0 2.0 29.69911764705882 0.75 48.0 19.0 56.0\n",
      " 29.69911764705882 23.0 29.69911764705882 18.0 21.0 29.69911764705882 18.0\n",
      " 24.0 29.69911764705882 32.0 23.0 58.0 50.0 40.0 47.0 36.0 20.0 32.0 25.0\n",
      " 29.69911764705882 43.0 29.69911764705882 40.0 31.0 70.0 31.0\n",
      " 29.69911764705882 18.0 24.5 18.0 43.0 36.0 29.69911764705882 27.0 20.0\n",
      " 14.0 60.0 25.0 14.0 19.0 18.0 15.0 31.0 4.0 29.69911764705882 25.0 60.0\n",
      " 52.0 44.0 29.69911764705882 49.0 42.0 18.0 35.0 18.0 25.0 26.0 39.0 45.0\n",
      " 42.0 22.0 29.69911764705882 24.0 29.69911764705882 48.0 29.0 52.0 19.0\n",
      " 38.0 27.0 29.69911764705882 33.0 6.0 17.0 34.0 50.0 27.0 20.0 30.0\n",
      " 29.69911764705882 25.0 25.0 29.0 11.0 29.69911764705882 23.0 23.0 28.5\n",
      " 48.0 35.0 29.69911764705882 29.69911764705882 29.69911764705882 36.0 21.0\n",
      " 24.0 31.0 70.0 16.0 30.0 19.0 31.0 4.0 6.0 33.0 23.0 48.0 0.67 28.0 18.0\n",
      " 34.0 33.0 29.69911764705882 41.0 20.0 36.0 16.0 51.0 29.69911764705882\n",
      " 30.5 29.69911764705882 32.0 24.0 48.0 57.0 29.69911764705882 54.0 18.0\n",
      " 29.69911764705882 5.0 29.69911764705882 43.0 13.0 17.0 29.0\n",
      " 29.69911764705882 25.0 25.0 18.0 8.0 1.0 46.0 29.69911764705882 16.0\n",
      " 29.69911764705882 29.69911764705882 25.0 39.0 49.0 31.0 30.0 30.0 34.0\n",
      " 31.0 11.0 0.42 27.0 31.0 39.0 18.0 39.0 33.0 26.0 39.0 35.0 6.0 30.5\n",
      " 29.69911764705882 23.0 31.0 43.0 10.0 52.0 27.0 38.0 27.0 2.0\n",
      " 29.69911764705882 29.69911764705882 1.0 29.69911764705882 62.0 15.0 0.83\n",
      " 29.69911764705882 23.0 18.0 39.0 21.0 29.69911764705882 32.0\n",
      " 29.69911764705882 20.0 16.0 30.0 34.5 17.0 42.0 29.69911764705882 35.0\n",
      " 28.0 29.69911764705882 4.0 74.0 9.0 16.0 44.0 18.0 45.0 51.0 24.0\n",
      " 29.69911764705882 41.0 21.0 48.0 29.69911764705882 24.0 42.0 27.0 31.0\n",
      " 29.69911764705882 4.0 26.0 47.0 33.0 47.0 28.0 15.0 20.0 19.0\n",
      " 29.69911764705882 56.0 25.0 33.0 22.0 28.0 25.0 39.0 27.0 19.0\n",
      " 29.69911764705882 26.0 32.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cleaning Data so that NaN gets filled with mean for age.\n",
    "print(\"Before Cleaning: \")\n",
    "print(x[:,1])\n",
    "# Imputer expects a 2D array, thus we need to transform our x from 1D to 2D \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "# Ravel reflattens 2D back to 1D for assignment\n",
    "x[:,1] = imputer.fit_transform(x[:,1].reshape(-1,1)).ravel()\n",
    "print(\"After Cleaning\")\n",
    "print(x[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d889e20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 22.0 3]\n",
      " [0 38.0 1]\n",
      " [0 26.0 3]\n",
      " ...\n",
      " [0 29.69911764705882 3]\n",
      " [1 26.0 1]\n",
      " [1 32.0 3]]\n"
     ]
    }
   ],
   "source": [
    "### Label Encoder \n",
    "le = LabelEncoder()\n",
    "x[:,0] = le.fit_transform(x[:,0])\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "175b9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training,test sets:\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5db3a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression Model:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(x_train,y_train.ravel())\n",
    "\n",
    "# Predicting with our test case\n",
    "# y_pred returned in 1D array\n",
    "y_pred = model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ec9d5884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91 15]\n",
      " [19 54]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix:\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred)\n",
    "\n",
    "# Result shows 90 Correct prediction of death, 21 wrong prediction of death\n",
    "# Shows 52 correct prediction of survival, 16 wrong predicton of survival\n",
    "# Overall a 79% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "96b03ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring how posisbly standardization of age could affect accuracy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "898fd962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202 -0.00541218 -1.55559305]\n",
      " [-1.36361202  0.29627125 -0.35949991]\n",
      " ...\n",
      " [ 0.73334642 -0.6841999  -0.35949991]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.6841999   0.83659324]]\n",
      "[[-1.36361202  1.35216325 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202 -0.98588332 -0.35949991]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [-1.36361202 -1.74009189 -0.35949991]\n",
      " [ 0.73334642 -0.6841999   0.83659324]\n",
      " [ 0.73334642  0.48482339 -0.35949991]\n",
      " [-1.36361202  0.3716921  -1.55559305]\n",
      " [ 0.73334642 -0.1562539  -1.55559305]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.38251647  0.83659324]\n",
      " [-1.36361202 -0.30709561  0.83659324]\n",
      " [ 0.73334642  1.80468839 -1.55559305]\n",
      " [ 0.73334642 -0.02810499 -0.35949991]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.1562539  -1.55559305]\n",
      " [ 0.73334642 -1.51382932  0.83659324]\n",
      " [ 0.73334642 -0.45793732  0.83659324]\n",
      " [ 0.73334642  0.44711296  0.83659324]\n",
      " [-1.36361202 -0.45793732 -0.35949991]\n",
      " [ 0.73334642  0.14542953  0.83659324]\n",
      " [ 0.73334642 -0.30709561  0.83659324]\n",
      " [-1.36361202 -0.45793732 -1.55559305]\n",
      " [ 0.73334642 -0.91046247 -0.35949991]\n",
      " [-1.36361202 -1.17443547  0.83659324]\n",
      " [ 0.73334642 -0.23167475  0.83659324]\n",
      " [-1.36361202 -0.6841999  -1.55559305]\n",
      " [-1.36361202  0.8996381  -0.35949991]\n",
      " [ 0.73334642 -0.30709561 -0.35949991]\n",
      " [-1.36361202 -0.60877904 -1.55559305]\n",
      " [-1.36361202 -0.60877904  0.83659324]\n",
      " [ 0.73334642 -0.02810499 -1.55559305]\n",
      " [-1.36361202  0.67337553  0.83659324]\n",
      " [-1.36361202 -0.38251647  0.83659324]\n",
      " [ 0.73334642  0.78650682  0.83659324]\n",
      " [-1.36361202 -1.89093361  0.83659324]\n",
      " [ 0.73334642  0.44711296 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.38251647 -1.55559305]\n",
      " [ 0.73334642 -0.75962075  0.83659324]\n",
      " [-1.36361202 -0.23167475  0.83659324]\n",
      " [-1.36361202 -0.23167475  0.83659324]\n",
      " [-1.36361202  1.27674239 -1.55559305]\n",
      " [ 0.73334642  1.1636111  -1.55559305]\n",
      " [ 0.73334642 -2.19261704 -0.35949991]\n",
      " [ 0.73334642  0.3716921   0.83659324]\n",
      " [ 0.73334642 -1.43840847  0.83659324]\n",
      " [ 0.73334642  0.67337553 -0.35949991]\n",
      " [ 0.73334642  0.3716921  -1.55559305]\n",
      " [ 0.73334642 -1.06130418 -0.35949991]\n",
      " [ 0.73334642 -0.02810499 -0.35949991]\n",
      " [-1.36361202 -0.6841999  -0.35949991]\n",
      " [ 0.73334642 -0.83504161 -0.35949991]\n",
      " [ 0.73334642  0.44711296 -0.35949991]\n",
      " [ 0.73334642 -0.08083304  0.83659324]\n",
      " [-1.36361202 -0.45793732  0.83659324]\n",
      " [ 0.73334642 -0.08083304 -0.35949991]\n",
      " [ 0.73334642  2.33263439 -1.55559305]\n",
      " [ 0.73334642  0.67337553  0.83659324]\n",
      " [-1.36361202 -0.75962075  0.83659324]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.1562539  -0.35949991]\n",
      " [ 0.73334642  1.12590067 -1.55559305]\n",
      " [ 0.73334642 -0.23167475 -1.55559305]\n",
      " [-1.36361202 -0.08083304  0.83659324]\n",
      " [ 0.73334642 -0.75962075  0.83659324]\n",
      " [ 0.73334642 -0.30709561  0.83659324]\n",
      " [-1.36361202 -2.11719618  0.83659324]\n",
      " [ 0.73334642  0.97505896 -0.35949991]\n",
      " [ 0.73334642 -0.45793732  0.83659324]\n",
      " [ 0.73334642 -1.2121459   0.83659324]\n",
      " [ 0.73334642  1.20132153 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202  2.03095096 -0.35949991]\n",
      " [ 0.73334642  0.07000868 -0.35949991]\n",
      " [-1.36361202  0.3716921  -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642  2.10637182 -1.55559305]\n",
      " [-1.36361202 -1.06130418 -1.55559305]\n",
      " [ 0.73334642 -0.30709561  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642  0.29627125  0.83659324]\n",
      " [-1.36361202 -0.53335818 -0.35949991]\n",
      " [ 0.73334642 -0.08083304  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202 -1.81551275  0.83659324]\n",
      " [-1.36361202 -0.00541218 -0.35949991]\n",
      " [ 0.73334642  1.27674239 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.38251647  0.83659324]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.00541218 -1.55559305]\n",
      " [ 0.73334642  2.18179267  0.83659324]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.83504161  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499 -1.55559305]\n",
      " [ 0.73334642  0.59795467 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202 -0.91046247  0.83659324]\n",
      " [-1.36361202 -1.06130418 -1.55559305]\n",
      " [ 0.73334642 -0.53335818  0.83659324]\n",
      " [ 0.73334642 -0.08083304  0.83659324]\n",
      " [ 0.73334642 -0.08083304  0.83659324]\n",
      " [ 0.73334642 -1.74009189  0.83659324]\n",
      " [ 0.73334642  0.8996381   0.83659324]\n",
      " [ 0.73334642  1.4275841  -1.55559305]\n",
      " [ 0.73334642 -0.60877904  0.83659324]\n",
      " [ 0.73334642  1.35216325 -0.35949991]\n",
      " [ 0.73334642 -0.38251647  0.83659324]\n",
      " [ 0.73334642 -0.53335818 -0.35949991]\n",
      " [ 0.73334642  0.22085039  0.83659324]\n",
      " [ 0.73334642 -0.08083304 -0.35949991]\n",
      " [ 0.73334642  0.07000868 -1.55559305]\n",
      " [-1.36361202  0.44711296 -0.35949991]\n",
      " [-1.36361202  0.07000868  0.83659324]\n",
      " [-1.36361202 -0.1562539  -0.35949991]\n",
      " [ 0.73334642  1.65384667 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.91046247 -0.35949991]\n",
      " [-1.36361202  0.07000868 -1.55559305]\n",
      " [-1.36361202 -0.83504161 -1.55559305]\n",
      " [-1.36361202 -0.1562539  -0.35949991]\n",
      " [-1.36361202 -0.60877904  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.45793732  0.83659324]\n",
      " [ 0.73334642  1.05047982  0.83659324]\n",
      " [-1.36361202 -2.21147225  0.83659324]\n",
      " [ 0.73334642 -0.23167475 -1.55559305]\n",
      " [-1.36361202  0.22085039  0.83659324]\n",
      " [-1.36361202  2.10637182 -1.55559305]\n",
      " [-1.36361202 -0.91046247 -1.55559305]\n",
      " [ 0.73334642 -2.19261704  0.83659324]\n",
      " [ 0.73334642 -0.91046247  0.83659324]\n",
      " [-1.36361202 -0.53335818  0.83659324]\n",
      " [-1.36361202 -0.38251647 -1.55559305]\n",
      " [ 0.73334642  0.67337553  0.83659324]\n",
      " [-1.36361202 -1.2121459  -1.55559305]\n",
      " [-1.36361202 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202 -0.91046247  0.83659324]\n",
      " [ 0.73334642  0.07000868 -0.35949991]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [-1.36361202  0.67337553  0.83659324]\n",
      " [ 0.73334642 -0.60877904  0.83659324]\n",
      " [-1.36361202 -2.11719618  0.83659324]\n",
      " [ 0.73334642  1.4275841   0.83659324]\n",
      " [ 0.73334642 -2.11719618  0.83659324]\n",
      " [-1.36361202 -0.60877904  0.83659324]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642  0.14542953  0.83659324]\n",
      " [ 0.73334642 -0.60877904  0.83659324]\n",
      " [ 0.73334642  0.8996381   0.83659324]\n",
      " [-1.36361202 -0.23167475 -0.35949991]\n",
      " [ 0.73334642 -0.53335818 -0.35949991]\n",
      " [ 0.73334642  0.52253382 -0.35949991]\n",
      " [ 0.73334642 -0.1562539   0.83659324]\n",
      " [-1.36361202 -0.6841999   0.83659324]\n",
      " [ 0.73334642 -0.1562539  -1.55559305]\n",
      " [ 0.73334642 -0.30709561  0.83659324]\n",
      " [-1.36361202 -1.13672504  0.83659324]\n",
      " [-1.36361202 -0.45793732 -0.35949991]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -1.06130418  0.83659324]\n",
      " [ 0.73334642  2.10637182 -1.55559305]\n",
      " [-1.36361202  0.3716921  -1.55559305]\n",
      " [-1.36361202 -2.11719618  0.83659324]\n",
      " [-1.36361202 -0.00541218 -1.55559305]\n",
      " [ 0.73334642 -0.91046247  0.83659324]\n",
      " [-1.36361202  1.4275841  -1.55559305]\n",
      " [ 0.73334642 -0.02810499 -1.55559305]\n",
      " [ 0.73334642 -0.02810499  0.83659324]\n",
      " [ 0.73334642 -0.6841999   0.83659324]\n",
      " [-1.36361202 -1.89093361  0.83659324]]\n",
      "[[91 15]\n",
      " [19 54]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Training again on standardize x \n",
    "print(x_train)\n",
    "print(x_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(x_train,y_train.ravel())\n",
    "\n",
    "# Predicting with our test case\n",
    "# y_pred returned in 1D array\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bfa0d",
   "metadata": {},
   "source": [
    "After Standardizing all independent variable of X, didn't see a change in accuracy of the logistical regression modal. So time to explore other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e80d66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97  9]\n",
      " [32 41]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.770949720670391"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN Model:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kModel = KNeighborsClassifier(n_neighbors=5,metric=\"minkowski\", p=2)\n",
    "kModel.fit(x_train,y_train.ravel())\n",
    "y_pred_2 = kModel.predict(x_test)\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred_2)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred_2)\n",
    "\n",
    "# Model Did worse apparently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f48d0a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 16]\n",
      " [24 49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.776536312849162"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM MODEL\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel = 'linear', random_state = 0)\n",
    "svm_model .fit(x_train, y_train.ravel())\n",
    "y_pred_3 =  svm_model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred_3)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ffd24ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   6]\n",
      " [ 38  35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7541899441340782"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(kernel = 'rbf', random_state = 0)\n",
    "svc_model.fit(x_train, y_train.ravel())\n",
    "y_pred_4 = svc_model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred_4)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d6908667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89 17]\n",
      " [24 49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.770949720670391"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian_model = GaussianNB()\n",
    "gaussian_model.fit(x_train, y_train.ravel())\n",
    "y_pred_5 = gaussian_model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred_5)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "807c53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 12]\n",
      " [28 45]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.776536312849162"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_model = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dtree_model.fit(x_train, y_train.ravel())\n",
    "y_pred_6 = dtree_model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred_6)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred_6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f78ba1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82 24]\n",
      " [26 47]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7206703910614525"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rforest_model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "rforest_model.fit(x_train, y_train.ravel())\n",
    "y_pred_7 = rforest_model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test.ravel(),y_pred_7)\n",
    "print(cm)\n",
    "accuracy_score(y_test.ravel(),y_pred_7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
